pcv_scores <- as.data.frame(pc_v$scores[,1:i])
train_df <- data.frame(pc_t$scores[,1:i])
t_names = {}
for(q in 1:i){
t_names = append(t_names, paste("pc", q, sep=""))
}
tdf <- cbind(pct_scores, quality = reds_train_train$quality)
vdf <- cbind(pcv_scores, quality = reds_train_val$quality)
model_olr <- MASS:polr(quality ~ ., data=tdf) # Only difference from above block
CV_tmp_a_olr[k] <- sum(predict(model_multi, newdata= vdf) != reds_train_val$quality) / nrow(vdf)
CV_tmp_b_olr[k] <- sum((as.numeric(predict(model_multi, newdata = vdf)) - as.numeric(vdf$quality))^2)
}
CV_plot_a_olr[i] = mean(CV_tmp_a_olr)
CV_plot_b_olr[i] = mean(CV_tmp_b_olr)/nrow(vdf)
}
Q=10
for(i in 1:Q){
CV_tmp_a_olr <- {}
CV_tmp_b_olr <- {}
for(j in 1:10){
reds_train_train = reds_train[!(ids == k),]
reds_train_val = reds_train[ids == k,]
pc_t <- princomp(reds_train_train[,1:11],cor=T)
pct_scores <- as.data.frame(pc_t$scores[,1:i])
pc_v <- princomp(reds_train_val[,1:11],cor=T)
pcv_scores <- as.data.frame(pc_v$scores[,1:i])
train_df <- data.frame(pc_t$scores[,1:i])
t_names = {}
for(q in 1:i){
t_names = append(t_names, paste("pc", q, sep=""))
}
tdf <- cbind(pct_scores, quality = reds_train_train$quality)
vdf <- cbind(pcv_scores, quality = reds_train_val$quality)
model_olr <- MASS::polr(quality ~ ., data=tdf) # Only difference from above block
CV_tmp_a_olr[k] <- sum(predict(model_multi, newdata= vdf) != reds_train_val$quality) / nrow(vdf)
CV_tmp_b_olr[k] <- sum((as.numeric(predict(model_multi, newdata = vdf)) - as.numeric(vdf$quality))^2)
}
CV_plot_a_olr[i] = mean(CV_tmp_a_olr)
CV_plot_b_olr[i] = mean(CV_tmp_b_olr)/nrow(vdf)
}
CV_tmp_a_olr <- {}
CV_tmp_b_olr <- {}
i
reds_train_train = reds_train[!(ids == k),]
reds_train_val = reds_train[ids == k,]
pc_t <- princomp(reds_train_train[,1:11],cor=T)
pct_scores <- as.data.frame(pc_t$scores[,1:i])
pc_v <- princomp(reds_train_val[,1:11],cor=T)
pcv_scores <- as.data.frame(pc_v$scores[,1:i])
train_df <- data.frame(pc_t$scores[,1:i])
t_names = {}
for(q in 1:i){
t_names = append(t_names, paste("pc", q, sep=""))
}
tdf <- cbind(pct_scores, quality = reds_train_train$quality)
vdf <- cbind(pcv_scores, quality = reds_train_val$quality)
model_olr <- MASS::polr(quality ~ ., data=tdf) # Only difference from above block
CV_tmp_a_olr[k] <- sum(predict(model_multi, newdata= vdf) != vdf$quality) / nrow(vdf)
vddf
vdf
Q=10
for(i in 1:Q){
CV_tmp_a_olr <- {}
CV_tmp_b_olr <- {}
for(j in 1:10){
reds_train_train = reds_train[!(ids == k),]
reds_train_val = reds_train[ids == k,]
pc_t <- princomp(reds_train_train[,1:11],cor=T)
pct_scores <- as.data.frame(pc_t$scores[,1:i])
pc_v <- princomp(reds_train_val[,1:11],cor=T)
pcv_scores <- as.data.frame(pc_v$scores[,1:i])
train_df <- data.frame(pc_t$scores[,1:i])
t_names = {}
for(q in 1:i){
t_names = append(t_names, paste("pc", q, sep=""))
}
names(pct_scores) <- t_names
names(pcv_scores) <- t_names
tdf <- cbind(pct_scores, quality = reds_train_train$quality)
vdf <- cbind(pcv_scores, quality = reds_train_val$quality)
model_olr <- MASS::polr(quality ~ ., data=tdf) # Only difference from above block
CV_tmp_a_olr[k] <- sum(predict(model_multi, newdata= vdf) != vdf$quality) / nrow(vdf)
CV_tmp_b_olr[k] <- sum((as.numeric(predict(model_multi, newdata = vdf)) - as.numeric(vdf$quality))^2)
}
CV_plot_a_olr[i] = mean(CV_tmp_a_olr)
CV_plot_b_olr[i] = mean(CV_tmp_b_olr)/nrow(vdf)
}
t_names
i
Q=10
for(i in 1:Q){
CV_tmp_a_olr <- {}
CV_tmp_b_olr <- {}
for(k in 1:10){
reds_train_train = reds_train[!(ids == k),]
reds_train_val = reds_train[ids == k,]
pc_t <- princomp(reds_train_train[,1:11],cor=T)
pct_scores <- as.data.frame(pc_t$scores[,1:i])
pc_v <- princomp(reds_train_val[,1:11],cor=T)
pcv_scores <- as.data.frame(pc_v$scores[,1:i])
train_df <- data.frame(pc_t$scores[,1:i])
t_names = {}
for(q in 1:i){
t_names = append(t_names, paste("pc", q, sep=""))
}
names(pct_scores) <- t_names
names(pcv_scores) <- t_names
tdf <- cbind(pct_scores, quality = reds_train_train$quality)
vdf <- cbind(pcv_scores, quality = reds_train_val$quality)
model_olr <- MASS::polr(quality ~ ., data=tdf) # Only difference from above block
CV_tmp_a_olr[k] <- sum(predict(model_multi, newdata= vdf) != vdf$quality) / nrow(vdf)
CV_tmp_b_olr[k] <- sum((as.numeric(predict(model_multi, newdata = vdf)) - as.numeric(vdf$quality))^2)
}
CV_plot_a_olr[i] = mean(CV_tmp_a_olr)
CV_plot_b_olr[i] = mean(CV_tmp_b_olr)/nrow(vdf)
}
k
for(q in 1:i){
t_names = append(t_names, paste("pc", q, sep=""))
}
t_names
i
tdf
tdf <- cbind(pct_scores, quality = reds_train_train$quality)
vdf <- cbind(pcv_scores, quality = reds_train_val$quality)
model_olr <- MASS::polr(quality ~ ., data=tdf) # Only difference from above block
CV_tmp_a_olr[k] <- sum(predict(model_multi, newdata= vdf) != vdf$quality) / nrow(vdf)
Q=10
for(i in 1:Q){
CV_tmp_a_olr <- {}
CV_tmp_b_olr <- {}
for(k in 1:10){
reds_train_train = reds_train[!(ids == k),]
reds_train_val = reds_train[ids == k,]
pc_t <- princomp(reds_train_train[,1:11],cor=T)
pct_scores <- as.data.frame(pc_t$scores[,1:i])
pc_v <- princomp(reds_train_val[,1:11],cor=T)
pcv_scores <- as.data.frame(pc_v$scores[,1:i])
train_df <- data.frame(pc_t$scores[,1:i])
t_names = {}
for(q in 1:i){
t_names = append(t_names, paste("pc", q, sep=""))
}
names(pct_scores) <- t_names
names(pcv_scores) <- t_names
tdf <- cbind(pct_scores, quality = reds_train_train$quality)
vdf <- cbind(pcv_scores, quality = reds_train_val$quality)
model_olr <- MASS::polr(quality ~ ., data=tdf) # Only difference from above block
CV_tmp_a_olr[k] <- sum(predict(model_olr, newdata= vdf) != vdf$quality) / nrow(vdf)
CV_tmp_b_olr[k] <- sum((as.numeric(predict(model_olr, newdata = vdf)) - as.numeric(vdf$quality))^2)
}
CV_plot_a_olr[i] = mean(CV_tmp_a_olr)
CV_plot_b_olr[i] = mean(CV_tmp_b_olr)/nrow(vdf)
}
Q=10
CV_plot_a_olr[i] = {}
Q=10
CV_plot_a_olr = {}
CV_plot_b_olr = {}
for(i in 1:Q){
CV_tmp_a_olr <- {}
CV_tmp_b_olr <- {}
for(k in 1:10){
reds_train_train = reds_train[!(ids == k),]
reds_train_val = reds_train[ids == k,]
pc_t <- princomp(reds_train_train[,1:11],cor=T)
pct_scores <- as.data.frame(pc_t$scores[,1:i])
pc_v <- princomp(reds_train_val[,1:11],cor=T)
pcv_scores <- as.data.frame(pc_v$scores[,1:i])
train_df <- data.frame(pc_t$scores[,1:i])
t_names = {}
for(q in 1:i){
t_names = append(t_names, paste("pc", q, sep=""))
}
names(pct_scores) <- t_names
names(pcv_scores) <- t_names
tdf <- cbind(pct_scores, quality = reds_train_train$quality)
vdf <- cbind(pcv_scores, quality = reds_train_val$quality)
model_olr <- MASS::polr(quality ~ ., data=tdf) # Only difference from above block
CV_tmp_a_olr[k] <- sum(predict(model_olr, newdata= vdf) != vdf$quality) / nrow(vdf)
CV_tmp_b_olr[k] <- sum((as.numeric(predict(model_olr, newdata = vdf)) - as.numeric(vdf$quality))^2)
}
CV_plot_a_olr[i] = mean(CV_tmp_a_olr)
CV_plot_b_olr[i] = mean(CV_tmp_b_olr)/nrow(vdf)
}
plot(1:Q, CV_plot_a, type = "b", pch=19, main = "10-fold CV with Two Different Metrics",
ylab = "Prediction Error Rate", xlab = "# of Principal Components")
par(new=T)
plot(1:Q, CV_plot_a_olr, type = "b", col = "blue", ylab="", xlab = "", axes=F, pch=19)
plot(1:Q, CV_plot_a, type = "b", pch=19, main = "10-fold CV for Ordinal LR and Multinomial LR",
ylab = "Prediction Error Rate", xlab = "# of Principal Components")
par(new=T)
plot(1:Q, CV_plot_a_olr, type = "b", col = "blue", ylab="", xlab = "", axes=F, pch=19)
plot(1:Q, CV_plot_a, type = "b", pch=19, main = "10-fold CV for Ordinal LR and Multinomial LR",
ylab = "Prediction Error Rate", xlab = "# of Principal Components")
par(new=T)
plot(1:Q, CV_plot_a_olr, type = "b", col = "blue", ylab="", xlab = "", axes=F, pch=19)
legend(legend = c("Multinomial", "Ordinal"), col = c("black", "blue"))
plot(1:Q, CV_plot_a, type = "b", pch=19, main = "10-fold CV for Ordinal LR and Multinomial LR",
ylab = "Prediction Error Rate", xlab = "# of Principal Components")
par(new=T)
plot(1:Q, CV_plot_a_olr, type = "b", col = "blue", ylab="", xlab = "", axes=F, pch=19)
legend(1,95,legend = c("Multinomial", "Ordinal"), col = c("black", "blue"))
plot(1:Q, CV_plot_a, type = "b", pch=19, main = "10-fold CV for Ordinal LR and Multinomial LR",
ylab = "Prediction Error Rate", xlab = "# of Principal Components")
par(new=T)
plot(1:Q, CV_plot_a_olr, type = "b", col = "blue", ylab="", xlab = "", axes=F, pch=19)
legend(10,.57,legend = c("Multinomial", "Ordinal"), col = c("black", "blue"))
plot(1:Q, CV_plot_a, type = "b", pch=19, main = "10-fold CV for Ordinal LR and Multinomial LR",
ylab = "Prediction Error Rate", xlab = "# of Principal Components")
par(new=T)
plot(1:Q, CV_plot_a_olr, type = "b", col = "blue", ylab="", xlab = "", axes=F, pch=19)
legend(10,.5,legend = c("Multinomial", "Ordinal"), col = c("black", "blue"))
plot(1:Q, CV_plot_a, type = "b", pch=19, main = "10-fold CV for Ordinal LR and Multinomial LR",
ylab = "Prediction Error Rate", xlab = "# of Principal Components")
par(new=T)
plot(1:Q, CV_plot_a_olr, type = "b", col = "blue", ylab="", xlab = "", axes=F, pch=19)
legend(7,.54,legend = c("Multinomial", "Ordinal"), col = c("black", "blue"))
plot(1:Q, CV_plot_a, type = "b", pch=19, main = "10-fold CV for Ordinal LR and Multinomial LR",
ylab = "Prediction Error Rate", xlab = "# of Principal Components")
par(new=T)
plot(1:Q, CV_plot_a_olr, type = "b", col = "blue", ylab="", xlab = "", axes=F, pch=19)
legend(7,.54,legend = c("Multinomial", "Ordinal"), col = c("black", "blue"), lty = 1:2)
plot(1:Q, CV_plot_a, type = "b", pch=19, main = "10-fold CV for Ordinal LR and Multinomial LR",
ylab = "Prediction Error Rate", xlab = "# of Principal Components")
par(new=T)
plot(1:Q, CV_plot_a_olr, type = "b", col = "blue", ylab="", xlab = "", axes=F, pch=19)
legend(7,.54,legend = c("Multinomial", "Ordinal"), col = c("black", "blue"), lty = 1:1)
plot(1:Q, CV_plot_b, type = "b", pch=19, main = "10-fold CV for Ordinal LR and Multinomial LR",
ylab = "MSE", xlab = "# of Principal Components")
par(new=T)
plot(1:Q, CV_plot_b_olr, type = "b", col = "blue", ylab="", xlab = "", axes=F, pch=19)
legend(7,.54,legend = c("Multinomial", "Ordinal"), col = c("black", "blue"), lty = 1:1)
plot(1:Q, CV_plot_b, type = "b", pch=19, main = "10-fold CV for Ordinal LR and Multinomial LR",
ylab = "MSE", xlab = "# of Principal Components")
par(new=T)
plot(1:Q, CV_plot_b_olr, type = "b", col = "blue", ylab="", xlab = "", axes=F, pch=19)
legend(7,.75,legend = c("Multinomial", "Ordinal"), col = c("black", "blue"), lty = 1:1)
plot(1:Q, CV_plot_b, type = "b", pch=19, main = "10-fold CV for Ordinal LR and Multinomial LR",
ylab = "MSE", xlab = "# of Principal Components")
par(new=T)
plot(1:Q, CV_plot_b_olr, type = "b", col = "blue", ylab="", xlab = "", axes=F, pch=19)
legend(7,.7,legend = c("Multinomial", "Ordinal"), col = c("black", "blue"), lty = 1:1)
# Cross Validation: # of PC's
set.seed(42)
ids <- sample(1:10, nrow(reds_train), replace = TRUE)
CV_plot_a <- {}
CV_plot_b <- {}
Q = 11
for(i in 1:Q){
CV_tmp_a <- {}
CV_tmp_b <- {}
for(k in 1:10){
reds_train_train = reds_train[!(ids == k),]
reds_train_val = reds_train[ids == k,]
pc_t <- princomp(reds_train_train[,1:11],cor=T)
pct_scores <- as.data.frame(pc_t$scores[,1:i])
pc_v <- princomp(reds_train_val[,1:11],cor=T)
pcv_scores <- as.data.frame(pc_v$scores[,1:i])
train_df <- data.frame(pc_t$scores[,1:i])
t_names = {}
for(q in 1:i){
t_names = append(t_names, paste("pc", q, sep=""))
}
names(pct_scores) <- t_names
names(pcv_scores) <- t_names
tdf <- cbind(pct_scores, quality = reds_train_train$quality)
vdf <- cbind(pcv_scores, quality = reds_train_val$quality)
model_multi <- nnet::multinom(quality ~ . , data = tdf)
CV_tmp_a[k] <- sum(predict(model_multi, newdata= vdf) != reds_train_val$quality) / nrow(vdf)
CV_tmp_b[k] <- sum((as.numeric(predict(model_multi, newdata = vdf)) - as.numeric(vdf$quality))^2)
}
CV_plot_a[i] = mean(CV_tmp_a)
CV_plot_b[i] = mean(CV_tmp_b)/nrow(vdf)
}
plot(1:Q, CV_plot_a, type = "b", pch=19, main = "10-fold CV with Two Different Metrics",
ylab = "Prediction Error Rate", xlab = "# of Principal Components")
par(new=T)
plot(1:Q, CV_plot_b, type = "b", col = "red", ylab="", xlab = "", axes=F, pch=15)
axis(4, col="red", col.axis="red")
mtext(side=4, "MSE", col = "red", line = -2)
Q=11
CV_plot_a_olr = {}
CV_plot_b_olr = {}
for(i in 1:Q){
CV_tmp_a_olr <- {}
CV_tmp_b_olr <- {}
for(k in 1:10){
reds_train_train = reds_train[!(ids == k),]
reds_train_val = reds_train[ids == k,]
pc_t <- princomp(reds_train_train[,1:11],cor=T)
pct_scores <- as.data.frame(pc_t$scores[,1:i])
pc_v <- princomp(reds_train_val[,1:11],cor=T)
pcv_scores <- as.data.frame(pc_v$scores[,1:i])
train_df <- data.frame(pc_t$scores[,1:i])
t_names = {}
for(q in 1:i){
t_names = append(t_names, paste("pc", q, sep=""))
}
names(pct_scores) <- t_names
names(pcv_scores) <- t_names
tdf <- cbind(pct_scores, quality = reds_train_train$quality)
vdf <- cbind(pcv_scores, quality = reds_train_val$quality)
model_olr <- MASS::polr(quality ~ ., data=tdf) # Only difference from above block
CV_tmp_a_olr[k] <- sum(predict(model_olr, newdata= vdf) != vdf$quality) / nrow(vdf)
CV_tmp_b_olr[k] <- sum((as.numeric(predict(model_olr, newdata = vdf)) - as.numeric(vdf$quality))^2)
}
CV_plot_a_olr[i] = mean(CV_tmp_a_olr)
CV_plot_b_olr[i] = mean(CV_tmp_b_olr)/nrow(vdf)
}
plot(1:Q, CV_plot_a, type = "b", pch=19, main = "10-fold CV for Ordinal LR and Multinomial LR",
ylab = "Prediction Error Rate", xlab = "# of Principal Components")
par(new=T)
plot(1:Q, CV_plot_a_olr, type = "b", col = "blue", ylab="", xlab = "", axes=F, pch=19)
legend(7,.54,legend = c("Multinomial", "Ordinal"), col = c("black", "blue"), lty = 1:1)
plot(1:Q, CV_plot_b, type = "b", pch=19, main = "10-fold CV for Ordinal LR and Multinomial LR",
ylab = "MSE", xlab = "# of Principal Components")
par(new=T)
plot(1:Q, CV_plot_b_olr, type = "b", col = "blue", ylab="", xlab = "", axes=F, pch=19)
legend(7,.7,legend = c("Multinomial", "Ordinal"), col = c("black", "blue"), lty = 1:1)
which.min(CV_plot_a_olr)
CV_plot_b[3]
CV_plot_b_olr[3]
model_olr_final <- MASS::polr(quality ~ ., data=reds_train)
plot(as.numeric(reds_train$quality), model_olr_final$fitted.values)
model_olr_final <- MASS::polr(quality ~ ., data=reds_train)
plot(as.numeric(reds_train$quality), model_olr_final$fitted.values)
as.numeric(reds_train$quality)
model_olr_final$fitted.values
guesses <- predict(model_olr_final, newdata=reds_test)
model_olr_final <- MASS::polr(quality ~ ., data=reds_train)
plot(as.numeric(reds_train$quality), model_olr_final$fitted.values)
guesses
predict(model_olr_final, newdata=reds_train)
plot(as.numeric(reds_train$quality), train_guesses)
train_guesses <- as.numeric(predict(model_olr_final, newdata=reds_train))
plot(as.numeric(reds_train$quality), train_guesses)
plot(as.numeric(reds_train$quality), train_guesses-as.numeric(reds_train$quality))
plot(as.numeric(reds_train$quality), train_guesses-as.numeric(reds_train$quality), pch=19)
model_olr_final <- multinom(quality ~ ., data=reds_train)
train_guesses <- as.numeric(predict(model_olr_final, newdata=reds_train))
plot(as.numeric(reds_train$quality), train_guesses-as.numeric(reds_train$quality), pch=19)
pc_t <- princomp(reds_train[,1:11],cor=T)
View(pct_scores)
pc_t <- princomp(reds_train[,1:11],cor=T)
pct_scores <- as.data.frame(pc_t$scores[,1:i])
t_names = {}
for(q in 1:i){
t_names = append(t_names, paste("pc", q, sep=""))
}
names(pct_scores) <- t_names
pct_scores
pct_scores <- pct_scores[,1:3]
pct_scores
tdf <- cbind(pct_scores, reds_train$quality)
model_olr_final <- multinom(quality ~ ., data=tdf)
tdf <- cbind(pct_scores, reds_train$quality)
model_olr_final <- multinom(quality ~ ., data=tdf)
rm(tdf)
pc_t <- princomp(reds_train[,1:11],cor=T)
pct_scores <- as.data.frame(pc_t$scores[,1:i])
t_names = {}
for(q in 1:i){
t_names = append(t_names, paste("pc", q, sep=""))
}
names(pct_scores) <- t_names
pct_scores <- pct_scores[,1:3]
tdf <- cbind(pct_scores, quality=reds_train$quality)
model_olr_final <- multinom(quality ~ ., data=tdf)
train_guesses <- as.numeric(predict(model_olr_final, newdata=reds_train))
plot(as.numeric(reds_train$quality), train_guesses-as.numeric(reds_train$quality), pch=19)
train_guesses <- as.numeric(predict(model_olr_final, newdata=reds_train))
pc_t <- princomp(reds_train[,1:11],cor=T)
pct_scores <- as.data.frame(pc_t$scores[,1:3])
names(pct_scores) <- c("pc1","pc2", "pc3")
tdf <- cbind(pct_scores, quality=reds_train$quality)
model_olr_final <- multinom(quality ~ ., data=tdf)
pc_test <- princomp(reds_test[,1:11],cor=T)
pctest_scores <- as.data.frame(pc_t$scores[,1:3])
names(pctest_scores) <- c("pc1","pc2", "pc3")
pctest_scores <- as.data.frame(pc_t$scores[,1:3])
names(pctest_scores) <- c("pc1","pc2", "pc3")
testdf <- cbind(pctest_scores, quality=reds_test$quality)
pc_test <- princomp(reds_test[,1:11],cor=T)
pctest_scores <- as.data.frame(pc_t$scores[,1:3])
names(pctest_scores) <- c("pc1","pc2", "pc3")
testdf <- cbind(pctest_scores, quality=reds_test$quality)
pctest_scores
pctest_scores <- as.data.frame(pc_test$scores[,1:3])
names(pctest_scores) <- c("pc1","pc2", "pc3")
testdf <- cbind(pctest_scores, quality=reds_test$quality)
train_guesses <- as.numeric(predict(model_olr_final, newdata=vtestdf))
train_guesses <- as.numeric(predict(model_olr_final, newdata=testdf))
plot(as.numeric(reds_train$quality), train_guesses-as.numeric(reds_train$quality), pch=19)
# Train
pc_t <- princomp(reds_train[,1:11],cor=T)
pct_scores <- as.data.frame(pc_t$scores[,1:3])
names(pct_scores) <- c("pc1","pc2", "pc3")
tdf <- cbind(pct_scores, quality=reds_train$quality)
model_olr_final <- multinom(quality ~ ., data=tdf)
# Test
pc_test <- princomp(reds_test[,1:11],cor=T)
pctest_scores <- as.data.frame(pc_test$scores[,1:3])
names(pctest_scores) <- c("pc1","pc2", "pc3")
testdf <- cbind(pctest_scores, quality=reds_test$quality)
train_guesses <- as.numeric(predict(model_olr_final, newdata=testdf))
plot(as.numeric(reds_train$quality), train_guesses-as.numeric(reds_train$quality), pch=19,
main ="Residual Plot")
plot(as.numeric(reds_train$quality), train_guesses-as.numeric(reds_train$quality), pch=19,
main ="Residual Plot", xlab = "Quality", ylab= "Resiudals")
sum((as.numeric(predict(model_olr_final, newdata = testdf)) - as.numeric(testdf$quality))^2)
sum((as.numeric(predict(model_olr_final, newdata = testdf)) - as.numeric(testdf$quality))^2)/nrow(testdf)
sum(5.5 - as.numeric(testdf$quality))^2)/nrow(testdf)
sum(5.5 - as.numeric(testdf$quality))^2/nrow(testdf)
as.numeric(testdf$quality))
as.numeric(testdf$quality)
5.5 - as.numeric(testdf$quality)
sum(5.5 - as.numeric(testdf$quality)^2)/nrow(testdf)
sum((5.5 - as.numeric(testdf$quality))^2)/nrow(testdf)
sum((5.5 - as.numeric(testdf$quality))^2)/nrow(testdf)
# Part 2: Hearts
## Overview
sum((5.5 - as.numeric(testdf$quality))^2)/nrow(testdf)
plot(as.numeric(tdf$quality), 5.5-as.numeric(tdf$quality), pch=19,
main ="Residual Plot", xlab = "Quality", ylab= "Resiudals")
plot(as.numeric(tdf$quality), train_guesses-as.numeric(tdf$quality), pch=19,
main ="Residual Plot", xlab = "Quality", ylab= "Resiudals")
plot(as.numeric(tdf$quality), train_guesses-as.numeric(tdf$quality), pch=19,
main ="Residual Plot", xlab = "Quality", ylab= "Resiudals")
plot(as.numeric(tdf$quality), 5.5-as.numeric(tdf$quality), pch=19,
main ="Residual Plot", xlab = "Quality", ylab= "Resiudals")
plot(as.numeric(tdf$quality), train_guesses-as.numeric(tdf$quality), pch=19,
main ="Residual Plot", xlab = "Quality", ylab= "Resiudals")
par(new=T)
plot(as.numeric(tdf$quality), 5.5-as.numeric(tdf$quality), pch=19,
main ="Residual Plot", xlab = "Quality", ylab= "Resiudals", col="red")
plot(as.numeric(tdf$quality), train_guesses-as.numeric(tdf$quality), pch=19,
main ="Residual Plot", xlab = "Quality", ylab= "Resiudals")
plot(as.numeric(tdf$quality), 5.5-as.numeric(tdf$quality), pch=19,
main ="Residual Plot", xlab = "Quality", ylab= "Resiudals", col="red")
plot(as.numeric(tdf$quality), train_guesses-as.numeric(tdf$quality), pch=19,
main ="Residual Plot", xlab = "Quality", ylab= "Resiudals")
par(new=T)
plot(as.numeric(tdf$quality), 5.5-as.numeric(tdf$quality), pch=19,
main ="Residual Plot", xlab = "Quality", ylab= "Resiudals", col="red")
# Train
pc_t <- princomp(reds_train[,1:11],cor=T)
pct_scores <- as.data.frame(pc_t$scores[,1:3])
names(pct_scores) <- c("pc1","pc2", "pc3")
tdf <- cbind(pct_scores, quality=reds_train$quality)
model_olr_final <- MASS::polr(quality ~ ., data=tdf)
# Test
pc_test <- princomp(reds_test[,1:11],cor=T)
pctest_scores <- as.data.frame(pc_test$scores[,1:3])
names(pctest_scores) <- c("pc1","pc2", "pc3")
testdf <- cbind(pctest_scores, quality=reds_test$quality)
train_guesses <- as.numeric(predict(model_olr_final, newdata=testdf))
plot(as.numeric(reds_train$quality), train_guesses-as.numeric(reds_train$quality), pch=19,
main ="Residual Plot", xlab = "Quality", ylab= "Resiudals")
sum((as.numeric(predict(model_olr_final, newdata = testdf)) - as.numeric(testdf$quality))^2)/nrow(testdf)
sum((5.5 - as.numeric(testdf$quality))^2)/nrow(testdf)
plot(as.numeric(tdf$quality), train_guesses-as.numeric(tdf$quality), pch=19,
main ="Residual Plot", xlab = "Quality", ylab= "Resiudals")
par(new=T)
plot(as.numeric(tdf$quality), 5.5-as.numeric(tdf$quality), pch=19,
main ="Residual Plot", xlab = "Quality", ylab= "Resiudals", col="red")
plot(as.numeric(tdf$quality), 5.5-as.numeric(tdf$quality), pch=19,
main ="Residual Plot", xlab = "Quality", ylab= "Resiudals", col="red",
axes=F)
plot(as.numeric(tdf$quality), train_guesses-as.numeric(tdf$quality), pch=19,
main ="Residual Plot", xlab = "Quality", ylab= "Resiudals")
par(new=T)
plot(as.numeric(tdf$quality), 5.5-as.numeric(tdf$quality), pch=19,
main ="Residual Plot", xlab = "Quality", ylab= "Resiudals", col="red")
# Cross Validation: # of PC's
set.seed(42)
ids <- sample(1:10, nrow(reds_train), replace = TRUE)
CV_plot_a <- {}
CV_plot_b <- {}
Q = 11
for(i in 1:Q){
CV_tmp_a <- {}
CV_tmp_b <- {}
for(k in 1:10){
reds_train_train = reds_train[!(ids == k),]
reds_train_val = reds_train[ids == k,]
pc_t <- princomp(reds_train_train[,1:11],cor=T)
pct_scores <- as.data.frame(pc_t$scores[,1:i])
pc_v <- princomp(reds_train_val[,1:11],cor=T)
pcv_scores <- as.data.frame(pc_v$scores[,1:i])
train_df <- data.frame(pc_t$scores[,1:i])
t_names = {}
for(q in 1:i){
t_names = append(t_names, paste("pc", q, sep=""))
}
names(pct_scores) <- t_names
names(pcv_scores) <- t_names
tdf <- cbind(pct_scores, quality = reds_train_train$quality)
vdf <- cbind(pcv_scores, quality = reds_train_val$quality)
model_multi <- nnet::multinom(quality ~ . , data = tdf, trace = F)
CV_tmp_a[k] <- sum(predict(model_multi, newdata= vdf) != reds_train_val$quality) / nrow(vdf)
CV_tmp_b[k] <- sum((as.numeric(predict(model_multi, newdata = vdf)) - as.numeric(vdf$quality))^2)
}
CV_plot_a[i] = mean(CV_tmp_a)
CV_plot_b[i] = mean(CV_tmp_b)/nrow(vdf)
}
plot(1:Q, CV_plot_a, type = "b", pch=19, main = "10-fold CV with Two Different Metrics",
ylab = "Prediction Error Rate", xlab = "# of Principal Components")
par(new=T)
plot(1:Q, CV_plot_b, type = "b", col = "red", ylab="", xlab = "", axes=F, pch=15)
axis(4, col="red", col.axis="red")
mtext(side=4, "MSE", col = "red", line = -2)
