---
title: "Heart Disease"
author: "Liam Spoletini"
date: "8/10/2022"
output: html_document
---

# Heart Disease Classification

## Overview

### Dataset  
Name: **Heart Disease Data set**  

Response Variable:  
**Angiographic disease status**:  
0: <50% diameter narrowing  
1: >50% diameter narrowing  

Predictor Variables (13 total):  
Categorical:  
1. Sex  
0 = female  
1 = male  

2. Chest Pain Type (cp)  
1 = typical angina 
2 = atypical angina 
3 = non-anginal pain 
4 = asymptomatic 

3. Fasting Blood Sugar (fbs)  
0 = fbs < 120 mg/dl
1 = fbs > 120 mg/dl

4. Resting Electrocardiographic results (restecg)  
0 = normal  
1 = having ST-T wave abnormality (T wave inversions and/or ST elevation or depression of > 0.05 mV)   
2 = showing probable or definite left ventricular hypertrophy by Estes' criteria   

5. Exercise-Induced Angina (exang)  
0 = no  
1 = yes  

6. The slope of the peak exercise ST segment  (slope)  
1 = upsloping   
2 = flat   
3 = downsloping   

8. thal  
3 = normal  
6 = fixed defect  
7 = reversible defect   

Quantitative

1. Age  
2. resting blood pressure (in mm Hg on admission to the hospital) (trestbps)  
3. serum cholestoral in mg/dl (chol)  
4. maximum heart rate achieved (thalach)  
5. ST depression induced by exercise relative to rest (oldpeak)  
6. Number of major vessels (0-3) colored by flourosopy (ca)  

## Missing Data
```{r warning=FALSE}

heart_data %>% 
  mutate(ca = as.numeric(ca), thal = as.numeric(thal)) %>% 
  filter(!is.na(ca), !is.na(thal)) -> heart_data
dim(heart_data)


```
There are 297 instances without NA's.


### Train/Test Split

```{r}
n = nrow(heart_data)
set.seed(42)
Z <- sample(n,n/10)
heart_test = heart_data[Z,]
heart_train = heart_data[-Z,]
```

## Exploratory Data Analysis

```{r}
ggplot(heart_train) + 
  geom_point(aes(x= thalach, y = chol, color=factor(Number)))
```
```{r}
ggplot(heart_train) + 
  geom_point(aes(x= trestbps, y = chol, color=factor(Number)))
```

```{r}
ggplot(heart_train) + 
  geom_point(aes(x= thalach, y = trestbps, color=factor(Number)))
```
The data do not seem to be easily separable when looking at a low number of predictor variables.  Above are a subset of three such combinations of quantitative variables. It is possible that the data is still closer to linearly separable using more of the predictor variables at a time.  

## Machine Learning Methods: **Support Vector Machine**

### Formal Representation of Method:

Support Vector Machine classifiers rely on the idea of a hyperplane that divides the p-dimensional feature space.  This hyperplane is chosen to maximize the margin (the distance between the hyperplane and the training instances in the feature space).  In the case of Support Vector Machines, this hyperplane contains soft margins, and the cost function to be minimzed is a sum of all the violations of the soft margins.  The maximum sum of the cost function itself is a value that can be tuned to produce stricter or more lenient boundaries. 

### Assumptions/Considerations

The textbook doesn't mention any assumptions made about the data that are necessary for SVM.

## Tuning Parameter

The tuning parameter for Support Vector Machines is C, which is the maximum allowed sum of violations to the margin.  A lower value of C allows for fewer violations, and a higher value of C allows for more violations.  The type of kernel is another way we can tune the model.  If we transform the original data using a kernel, the SVM can create a boundary that is linear in the new feature space but nonlinear in the original feature space.  

## Implementation: SVM

Finding the optimal kernel and C combination:

Using 10-fold Cross-Validation on the training set
```{r}
set.seed(42)
rg <- list(kernel=c("linear","polynomial","radial","sigmoid"), cost=c(0.001, 0.01, 0.1, 1, 5, 10, 100))
svmt <- tune(svm, factor(Number) ~ .,data=heart_train, ranges = rg)
svmt
```

The optimal C in this grid was 10, with a linear kernel.

```{r}
rg2 <- list(kernel=c("linear","polynomial","radial","sigmoid"), cost=seq(5, 15, 0.5))
svmt <- tune(svm, factor(Number) ~ .,data=heart_train, ranges = rg2)
svmt
```

The finer grid identified an optimal C of 5.5.


## Testing on the Holdout Set

```{r}
svm.tuned <- svm(factor(Number) ~ ., kernel = "linear", cost = 5.5, data=heart_train)
yhat = predict(svm.tuned, newdata = heart_test[,1:13])
class <- data.frame(yhat = yhat,y = heart_test$Number)
table(class)
```

```{r}
pred <- prediction(as.numeric(yhat==1),as.numeric(heart_test$Number==1))
perf <- performance(pred,"auc")@y.values
perf
```

Summary Statistics:
Total error rate = 17.2%
AUC: 0.844

Through both the total error rate and the Area Under the Curve score, we can see that the SVM classifier is doing an okay job correctly identifying test set patients' heart disease status.  However, there are more false negatives in the dataset than false positives, and this is not the kind of classifier you want in a disease-detection setting. Below I will compare the results to a simple logistic regression model.

```{r}
log.model <- glm(factor(Number) ~ ., data=heart_train, family = "binomial")
yhat = predict(log.model, newdata= heart_test[,1:13], type = "response")
class <- data.frame(yhat = as.numeric(yhat > 0.5),y = heart_test$Number)
table(class)
```

The logistic regression model has exactly the same distribution of predictions as the SVM model, which makes sense given the explanation of the two methods' relationship to each other detailed in the textbook.